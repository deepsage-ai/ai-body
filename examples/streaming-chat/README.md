# 流式对话示例

这是一个 AI-Body 流式传输探索示例，用于测试和学习 agent-sdk-go 框架的流式传输功能。

## 功能特点

- **流式传输测试**: 尝试使用真实的流式传输 API，如果不支持则自动回退到普通模式
- **彩色输出**: 使用不同颜色区分用户输入、AI回答、事件信息等
- **事件调试**: 显示流式事件的详细信息，便于理解 API 工作方式
- **完整上下文**: 保持对话历史和多租户支持
- **优雅降级**: 流式不可用时自动使用普通模式

## 运行方式

```bash
cd examples/streaming-chat
go run main.go
```

## 示例行为

### 如果流式传输可用
- 显示绿色的 `[使用流式传输]` 提示
- 实时显示 AI 回答内容（干净的输出，无调试信息）
- 完成后显示事件统计信息
- 真正的逐字符流式响应

### 如果流式传输不可用
- 显示黄色的 `[流式传输不可用，回退到普通模式]` 提示  
- 使用标准的 `agent.Run()` 方法
- 直接显示完整回答（不做任何模拟效果）

## 配置说明

- **Ollama 服务地址**: `http://10.20.88.156:11434/v1`
- **模型**: qwen3:32b
- **流式模式**: 启用
- **组织ID**: ai-body-streaming-demo
- **对话ID**: streaming-conversation-001

## 颜色说明

- 🔵 **蓝色**: 用户输入提示
- 🟣 **紫色**: AI回答
- 🟢 **绿色**: 系统提示和成功消息
- 🟡 **黄色**: 工具调用和警告
- 🔴 **红色**: 错误信息
- ⚪ **灰色**: 思考过程
- 🔷 **青色**: 标题和分割线

## 与简单示例的区别

1. **API 调用**: 尝试 `RunStream()` vs 直接使用 `Run()`
2. **事件处理**: 处理流式事件通道 vs 处理单一结果
3. **错误处理**: 优雅降级机制 vs 简单错误显示
4. **调试信息**: 显示事件详情 vs 纯净输出

## 学习价值

- **流式 API 探索**: 了解 agent-sdk-go 的流式传输能力
- **事件处理**: 学习如何处理异步事件流
- **优雅降级**: 学习如何处理 API 不可用的情况
- **调试技巧**: 通过事件详情了解框架内部工作机制

## 注意事项

这是一个**探索性示例**，流式传输的具体行为取决于：
- agent-sdk-go 框架的版本和实现
- 底层 LLM 提供商的流式支持
- Ollama 的 OpenAI 兼容接口实现